{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05023a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa \n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory, image \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.applications import VGG19, ResNet50\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, GlobalAveragePooling2D, InputLayer, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37c7fb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path.cwd()/'data'\n",
    "answers = pd.read_csv('answers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "693e8b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(which_path=2):\n",
    "    if which_path==1:\n",
    "        images_directory = path/'train_images'\n",
    "    else: \n",
    "        images_directory = path/'train_images2'\n",
    "    cb_training = image_dataset_from_directory(images_directory, labels='inferred', image_size=(97,97), subset='training', validation_split=.2, seed=10)\n",
    "    cb_validation = image_dataset_from_directory(images_directory, labels='inferred', image_size=(97,97), subset='validation', validation_split=.2, seed=10)\n",
    "    return (cb_training, cb_validation)\n",
    "\n",
    "\n",
    "def base_set_up(filename, patience=2):\n",
    "    \n",
    "    xx =compute_class_weight(class_weight='balanced',classes=np.unique(answers.label), y=answers.label)\n",
    "    class_weight = dict(zip(np.unique(answers.label), xx))\n",
    "    METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "    ]\n",
    "\n",
    "    earlystop = EarlyStopping(monitor='val_accuracy',verbose=1, patience=patience)\n",
    "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', save_best_only=True, save_weights_only=False, verbose=1)\n",
    "    return (class_weight, METRICS, earlystop, checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492d997b",
   "metadata": {},
   "source": [
    "# Try different Dense Layer on VGG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e484856c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30000 files belonging to 2 classes.\n",
      "Using 24000 files for training.\n",
      "Found 30000 files belonging to 2 classes.\n",
      "Using 6000 files for validation.\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/metis/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-22 17:51:54.554532: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 690s 918ms/step - loss: 3.8134 - tp: 3054.0000 - fp: 8285.0000 - tn: 10087.0000 - fn: 2574.0000 - accuracy: 0.5475 - precision: 0.2693 - recall: 0.5426 - auc: 0.5589 - prc: 0.2664 - val_loss: 0.6783 - val_tp: 1135.0000 - val_fp: 1649.0000 - val_tn: 2952.0000 - val_fn: 264.0000 - val_accuracy: 0.6812 - val_precision: 0.4077 - val_recall: 0.8113 - val_auc: 0.7959 - val_prc: 0.5061\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.68117, saving model to vgg19-cb-2.h5\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 1039s 1s/step - loss: 1.4842 - tp: 3149.0000 - fp: 7249.0000 - tn: 11123.0000 - fn: 2479.0000 - accuracy: 0.5947 - precision: 0.3028 - recall: 0.5595 - auc: 0.6160 - prc: 0.2981 - val_loss: 0.5156 - val_tp: 1053.0000 - val_fp: 1276.0000 - val_tn: 3325.0000 - val_fn: 346.0000 - val_accuracy: 0.7297 - val_precision: 0.4521 - val_recall: 0.7527 - val_auc: 0.7979 - val_prc: 0.4861\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.68117 to 0.72967, saving model to vgg19-cb-2.h5\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 1240s 2s/step - loss: 0.9106 - tp: 3082.0000 - fp: 6872.0000 - tn: 11500.0000 - fn: 2546.0000 - accuracy: 0.6076 - precision: 0.3096 - recall: 0.5476 - auc: 0.6308 - prc: 0.2950 - val_loss: 0.5013 - val_tp: 982.0000 - val_fp: 1145.0000 - val_tn: 3456.0000 - val_fn: 417.0000 - val_accuracy: 0.7397 - val_precision: 0.4617 - val_recall: 0.7019 - val_auc: 0.8017 - val_prc: 0.4840\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.72967 to 0.73967, saving model to vgg19-cb-2.h5\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 1323s 2s/step - loss: 0.7485 - tp: 3558.0000 - fp: 7592.0000 - tn: 10780.0000 - fn: 2070.0000 - accuracy: 0.5974 - precision: 0.3191 - recall: 0.6322 - auc: 0.6345 - prc: 0.2894 - val_loss: 0.5035 - val_tp: 1061.0000 - val_fp: 1292.0000 - val_tn: 3309.0000 - val_fn: 338.0000 - val_accuracy: 0.7283 - val_precision: 0.4509 - val_recall: 0.7584 - val_auc: 0.8021 - val_prc: 0.4856\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.73967\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 1294s 2s/step - loss: 0.6960 - tp: 4288.0000 - fp: 8893.0000 - tn: 9479.0000 - fn: 1340.0000 - accuracy: 0.5736 - precision: 0.3253 - recall: 0.7619 - auc: 0.6412 - prc: 0.2886 - val_loss: 0.4988 - val_tp: 1094.0000 - val_fp: 1391.0000 - val_tn: 3210.0000 - val_fn: 305.0000 - val_accuracy: 0.7173 - val_precision: 0.4402 - val_recall: 0.7820 - val_auc: 0.7967 - val_prc: 0.4628\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.73967\n",
      "Epoch 00005: early stopping\n"
     ]
    }
   ],
   "source": [
    "filename = 'vgg19-cb-2.h5'\n",
    "cb_training, cb_validation  = import_data()\n",
    "class_weight, METRICS, earlystop, checkpoint = base_set_up(filename)\n",
    "\n",
    "base_model2 = VGG19(weights='imagenet', include_top=False, input_shape=(97,97,3))\n",
    "for layer in base_model2.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x2 = base_model2.output\n",
    "x2 = Flatten()(x2)\n",
    "\n",
    "x2 = Dense(100, activation='relu')(x2)\n",
    "x2 = Dropout(.5)(x2)\n",
    "x2 = Dense(100, activation='relu')(x2)\n",
    "x2 = Dropout(.5)(x2)\n",
    "x2 = Dense(100, activation='relu')(x2)\n",
    "x2 = Dropout(.5)(x2)\n",
    "\n",
    "\n",
    "predictions2 = Dense(1, activation='sigmoid')(x2)\n",
    "optimizer = Adam(learning_rate=0.00001)\n",
    "\n",
    "model2 =  Model(inputs=base_model2.input, outputs=predictions2)\n",
    "model2.compile(optimizer=optimizer,loss='binary_crossentropy', metrics=METRICS)\n",
    "\n",
    "history2 = model2.fit(cb_training, epochs=10,validation_data=cb_validation, class_weight = class_weight, callbacks=[earlystop, checkpoint])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
