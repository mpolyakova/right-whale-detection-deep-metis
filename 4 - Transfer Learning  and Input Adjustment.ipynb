{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e10fcc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa \n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory, image \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, GlobalAveragePooling2D, InputLayer,Dropout\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff85baaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d278686",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path.cwd()/'data'\n",
    "answers = pd.read_csv('answers.csv')\n",
    "images_directory = path/'train_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "808abfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30000 files belonging to 2 classes.\n",
      "Using 24000 files for training.\n",
      "Found 30000 files belonging to 2 classes.\n",
      "Using 6000 files for validation.\n"
     ]
    }
   ],
   "source": [
    "cb_training = image_dataset_from_directory(images_directory, labels='inferred', image_size=(64,64), subset='training', validation_split=.2, seed=10)\n",
    "cb_validation = image_dataset_from_directory(images_directory, labels='inferred', image_size=(64,64), subset='validation', validation_split=.2, seed=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ca1e11",
   "metadata": {},
   "source": [
    "# summary so far\n",
    "## Overfitting \n",
    "So, we're grossly overfitting. That is a problem.   \n",
    "The false negatives for validation are going up, and recall is going down, continuously.  \n",
    "## What that means for our problem\n",
    "For our problem, the false negatives and recall are most important- missing a whale means we might hurt it - since there are only 400 of them in the world, thats a massive problem.  \n",
    "On the other hand, a false positive means ships in the area slow down without a whale being present. This is still pretty important - too many, and shipping will complain, or ignore requests to slow down. \n",
    "\n",
    "## What to do next \n",
    "There are 2 pathways I could take - 1 is to start optimizing.  \n",
    "But since I know CNN wont be our final model, I think thats too early. Most literature I've read uses transfer learning - its easier to start with a good baseline. So lets try that, and optimize from there. \n",
    "\n",
    "## Literature Review\n",
    "I've reviewed both blog posts, and papers regarding how to proceed, and whether transfer learning is helpful.  \n",
    "Most of the blog posts appear to create a CNN network without using transfer learning, however most don't describe their layer creation logic. \n",
    "## Layer Creation\n",
    "https://machinelearningmastery.com/how-to-configure-the-number-of-layers-and-nodes-in-a-neural-network/ \n",
    "https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw \n",
    "When choosing the number of layers, experimentation seems to be the most common approach, using existing work, and intuition, as well as literally brute forcing. I don't have the compute power to brute force, so lets go with utilizing transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52c0ec54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello World!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343f8297",
   "metadata": {},
   "source": [
    "# Transfer Learning \n",
    "## Papers\n",
    "### Rethinking CNN for Sounds \n",
    "Rethinking CNN Models for Audio Classification https://arxiv.org/pdf/2007.11154.pdf\n",
    "Comparison of Pre-Trained CNNs for Audio Classification Using Transfer Learning \n",
    "https://doi.org/10.3390/jsan10040072\n",
    "\n",
    "It looks like VGG has an excellect accuracy on various urban sounds datasets, and that transfer learning from ImageNet tends to work better than from scratch training. \n",
    "\n",
    "\n",
    "### Grouper Sound\n",
    "\n",
    "\"Transfer learning for efficient classification of grouper sound\" https://doi.org/10.1121/10.0001943 compared various transfer learning techniques for classifying underwater grouper sounds - the fish make specific sounds during spawning aggregations.   \n",
    "The paper compared various network models on multiple types of groupers, as well as comparing spectograms with scalograms and finding both performed similarly.\n",
    "Since this is underwater sound recognition, its quite similar to our problem. \n",
    "\n",
    "### Rainforest Animal Sounds \n",
    "\"Classification of animal sounds in a hyperdiverse rainforest using Convolutional Neural Networks\"  \n",
    "I found this paper incredibly helpful for data augmentation discussion, since visual representations of sounds are limited in how they can be augmented (before the picture represents a completely different sound). Also very helpful for experimentation on techniques. Very guiding! \n",
    "\n",
    "### Predicting Using Unbalanced Classes\n",
    "Our right whale to non- right whale (which we call no whale in code) sounds is about 1 to 5, so the class is a bit unbalanced. \n",
    "https://www.tensorflow.org/tutorials/structured_data/imbalanced_data \n",
    "https://towardsdatascience.com/dealing-with-imbalanced-data-in-tensorflow-class-weights-60f876911f99 \n",
    "I could balance the data using augmentation, but that would explode my dataset from 30K to amost 55K, which is a lot of images. Since I would like to use transfer learning to help with efficiency, I dont want to process on almost 2x data. It seems like class weights from tensorflow is a viable solution - adding attention to the whale class. \n",
    " \n",
    "### Cat Sounds \n",
    "CNN with Million song dataset- here, they are using a CNN to do feature extraction from cat sounds, and then actually running on classical classifiers on the features - Trees, LDA, Ensemble. The authors compare using a CNN with CDBN, and find them comparable, although it appears CDBN works slightly better. I like the slightly different approach to this problem. \n",
    "\n",
    "### Comparison \n",
    "https://towardsdatascience.com/the-w3h-of-alexnet-vggnet-resnet-and-inception-7baaaecccc96 \n",
    "\n",
    "\n",
    "## Steps \n",
    "Since both rainforest and grouper sounds aggregate that VGG19 trained on ImageNet performs well, I think I'd like to start there. Additionally I like the idea of reducing training time, I only have a little laptop after all \n",
    "\n",
    "1. Lets try \n",
    "2. Class weights - I guessed previously, now lets actually get the right weights\n",
    "3. The shape of the data. VGG19 expects 244 by 244 by default, and Im still operating on 64 by 64. To clean up and for consistenly, lets get it to 244\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4141c6d0",
   "metadata": {},
   "source": [
    "# Fix Input \n",
    "1. Copy original work from Notebook 2 \n",
    "2. Adjust the size of the graph\n",
    "3. Recreate(and overwrite) the existing spectrograms \n",
    "\n",
    "The original size was .72 inches, w/ a dpi of 400, \n",
    "400*.72 = 288\n",
    "I need 224, so adjust to .56\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "48c168bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sound(index, df):\n",
    "    row = df.iloc[index]\n",
    "    clip_path = row['clip_path']\n",
    "    image_path = row['image_path']\n",
    "    y, sr = librosa.load(clip_path, sr=None)\n",
    "    del clip_path, row\n",
    "    return y, sr, image_path \n",
    "\n",
    "def create_spectrogram(input_tuple):\n",
    "    y, sr, output_file = input_tuple\n",
    "    fig = plt.figure(figsize=[0.56, 0.56])\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    ax.set_frame_on(False)\n",
    "\n",
    "    spec = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    librosa.display.specshow(librosa.power_to_db(spec, ref=np.max))\n",
    "    plt.savefig(output_file, dpi=400, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "    fig.clf()\n",
    "    plt.close(fig)\n",
    "    plt.close('all')\n",
    "    del spec, fig, ax, y, sr, output_file, input_tuple\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b4c91f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 30000/30000 [31:22<00:00, 15.94it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(0, answers.shape[0])):\n",
    "    create_spectrogram(read_sound(i, answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c0fec2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30000 files belonging to 2 classes.\n",
      "Using 24000 files for training.\n",
      "Found 30000 files belonging to 2 classes.\n",
      "Using 6000 files for validation.\n"
     ]
    }
   ],
   "source": [
    "cb_training = image_dataset_from_directory(images_directory, labels='inferred', image_size=(64,64), subset='training', validation_split=.2, seed=10)\n",
    "cb_validation = image_dataset_from_directory(images_directory, labels='inferred', image_size=(64,64), subset='validation', validation_split=.2, seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df332555",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccda14f",
   "metadata": {},
   "source": [
    "# Model 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b431d2",
   "metadata": {},
   "source": [
    "## Bunches of Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84e9fe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225712de",
   "metadata": {},
   "source": [
    "## Class Weight Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ed14831",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xx =compute_class_weight(class_weight='balanced',classes=np.unique(answers.label), y=answers.label)\n",
    "class_weight = dict(zip(np.unique(answers.label), xx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5316db",
   "metadata": {},
   "source": [
    "## Model VGG19 Transfer Learning 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cdc5b5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "\n",
    "#Which should I try? \n",
    "# I liked the Jungle approach - they set up a custom function to do this - but for my first try, lets just take their patterns\n",
    "x = Dense(100, activation='relu')(x)\n",
    "x = Dropout(.3)(x)\n",
    "x = Dense(100, activation='relu')(x)\n",
    "x = Dropout(.3)(x)   \n",
    "predictions = Dense(1, activation='softmax')(x)\n",
    "\n",
    "model =  Model(inputs=base_model.input, outputs=predictions)\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy', metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20110103",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cbec89c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 47/750 [>.............................] - ETA: 3:05 - loss: 2.2916 - tp: 1035.0000 - fp: 3285.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2396 - precision: 0.2396 - recall: 1.0000 - auc: 0.5000 - prc: 0.2396"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9k/83m77rxs5835tnj2rh39wf3h0000gn/T/ipykernel_75056/2259224155.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/metis/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/metis/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/metis/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/metis/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/metis/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/opt/anaconda3/envs/metis/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/metis/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(cb_training, epochs=10,validation_data=cb_validation, class_weight = class_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bbc485",
   "metadata": {},
   "source": [
    "# Discussion on Size\n",
    "The size of the input severely limits how quickly I can train the model. However, my input is special - its not a true picture. Why would I make it so big, if the info in it can be put into smaller bits?  \n",
    "The spectrogram is small, because the sample rate of the sound is only 2kHz,and the sounds are short.  \n",
    "This means that I can summarize the entirety of the data into a much smaller size  \n",
    "And limit my input size, therefore speeding up my model. We can always make it bigger, but lets try to make it smaller first. \n",
    "\n",
    "# So, the images \n",
    "The images are only 8 across, but theyre tall - that, however, can be transformed in Librosa using the nfft parameter \n",
    "\n",
    "## Starting by Copying the Librosa Investigation in Notebook 1\n",
    "\n",
    "#So 128 produces a (65*126) whereas 256 produces a (129*63)\n",
    "#Can we train on a non-square image? https://stats.stackexchange.com/questions/240690/non-square-images-for-image-classification \n",
    "Based on this - yes but its not lovely. \n",
    "nfft parameter of 192 produces a 97 by 84 image - can we crop it to make it square? \n",
    "## Can we drop some of the signal from the sides?\n",
    "We would be dropping the vertical signal, which for this dataset sits between 0 and 1024. Since typical right whale characterizations falls below 1024, we can likely crop the images without concern. \n",
    "\n",
    "# Is this even allowed by VGG? Maaaybe?? Looks like generally a yes... \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fcfa8c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97, 84)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mfccs = librosa.feature.mfcc(y=y, sr=sr)\n",
    "which_file = 28\n",
    "filename1 = f'''train{which_file}.aiff'''\n",
    "filename1\n",
    "y, sr = librosa.load('data/train/'+filename1,sr=None)\n",
    "\n",
    "\n",
    "\n",
    "nfft=192\n",
    "#So 128 produces a (65*126) whereas 256 produces a (129*63)\n",
    "#Can we train on a non-square image? https://stats.stackexchange.com/questions/240690/non-square-images-for-image-classification \n",
    "\n",
    "\n",
    "\n",
    "Y0 = librosa.stft(y, n_fft=n_fft)\n",
    "#Window length explanation: https://dsp.stackexchange.com/questions/248/how-do-i-optimize-the-window-lengths-in-stft \n",
    "#Since we care about the frequency more than the time, we should keep the window default \n",
    "print(Y0.shape)\n",
    "Y = librosa.amplitude_to_db(Y0, ref=np.min )\n",
    "#librosa.display.specshow(Y,sr=sr,x_axis='time', y_axis='mel',n_fft=n_fft)\n",
    "#So generally, Melgrams - closer to the way we hear, perform better. However, these are whales, after all, underwater - will it actually perform better?? Or is what works for humans not ideal in this case? \n",
    "#Cat classificator uses mel spectrograms \n",
    "# https://en.wikipedia.org/wiki/Whale_vocalization \n",
    "#Right whales dont quite sing - they do an \"upcall\"\n",
    "#So - humans hear on the melscale. Maybe whales dont. But - in order to visualize better, I want to see the spectrogram better for humans\n",
    "#Same with amplitude\n",
    "fig = plt.figure(figsize=[10, 10])\n",
    "ax = fig.add_subplot(111)\n",
    "ax.axes.get_xaxis().set_visible(False)\n",
    "ax.axes.get_yaxis().set_visible(False)\n",
    "ax.set_frame_on(False)\n",
    "\n",
    "spec = librosa.stft(y, n_fft=n_fft)\n",
    "librosa.display.specshow(librosa.power_to_db(spec, ref=np.min),n_fft=n_fft)\n",
    "plt.savefig('temp.png', dpi=97, bbox_inches='tight', pad_inches=0)\n",
    "#Yep, all looks well "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b679eefc",
   "metadata": {},
   "source": [
    "# Do we have to Crop?  No\n",
    "Using the Tropical Rainforest paper, it appears it is acceptable to stretch the image - just not flip or turn it. \n",
    "\n",
    "so stretching it is! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfb9518",
   "metadata": {},
   "source": [
    "# Once More, We create the Spectrograms\n",
    "How Big? \n",
    "\n",
    "So: 97 by 97 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "93e78b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sound(index, df, feature=True):\n",
    "    row = df.iloc[index]\n",
    "    clip_path = row['clip_path']\n",
    "    if feature:\n",
    "        image_path = row['image_path']\n",
    "    else:\n",
    "        image_path = row['image_path2']\n",
    "    y, sr = librosa.load(clip_path, sr=None)\n",
    "    del clip_path, row\n",
    "    return y, sr, image_path, feature \n",
    "\n",
    "def create_spectrogram(input_tuple):\n",
    "    y, sr, output_file,feature = input_tuple\n",
    "    n_fft=192\n",
    "    \n",
    "    fig = plt.figure(figsize=[1, 1])\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    ax.set_frame_on(False)\n",
    "    if feature:\n",
    "        spec = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    else:\n",
    "         spec = librosa.stft(y, n_fft=n_fft)\n",
    "    librosa.display.specshow(librosa.power_to_db(spec, ref=np.min),n_fft=n_fft)\n",
    "    plt.savefig(output_file, dpi=97, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "    fig.clf()\n",
    "    plt.close(fig)\n",
    "    plt.close('all')\n",
    "    del spec, fig, ax, y, sr, output_file, input_tuple\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ed79199e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 30000/30000 [31:52<00:00, 15.69it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(0, answers.shape[0])):\n",
    "    create_spectrogram(read_sound(i, answers, feature=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe54888e",
   "metadata": {},
   "source": [
    "# Lets try the Model Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2850d585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30000 files belonging to 2 classes.\n",
      "Using 24000 files for training.\n",
      "Found 30000 files belonging to 2 classes.\n",
      "Using 6000 files for validation.\n"
     ]
    }
   ],
   "source": [
    "cb_training = image_dataset_from_directory(images_directory, labels='inferred', image_size=(97,97), subset='training', validation_split=.2, seed=10)\n",
    "cb_validation = image_dataset_from_directory(images_directory, labels='inferred', image_size=(97,97), subset='validation', validation_split=.2, seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "295dc71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xx =compute_class_weight(class_weight='balanced',classes=np.unique(answers.label), y=answers.label)\n",
    "class_weight = dict(zip(np.unique(answers.label), xx))\n",
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "27c98ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(97,97,3))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "\n",
    "#Which should I try? \n",
    "# I liked the Jungle approach - they set up a custom function to do this - but for my first try, lets just take their patterns\n",
    "x = Dense(100, activation='relu')(x)\n",
    "x = Dropout(.3)(x)\n",
    "x = Dense(100, activation='relu')(x)\n",
    "x = Dropout(.3)(x)   \n",
    "predictions = Dense(1, activation='softmax')(x)\n",
    "\n",
    "model =  Model(inputs=base_model.input, outputs=predictions)\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy', metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c7879a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "96e79e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "750/750 [==============================] - 738s 981ms/step - loss: 0.5774 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3308 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 2/100\n",
      "750/750 [==============================] - 666s 888ms/step - loss: 0.3959 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3476 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 3/100\n",
      "750/750 [==============================] - 653s 871ms/step - loss: 0.3655 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3140 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 4/100\n",
      "750/750 [==============================] - 645s 860ms/step - loss: 0.3607 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3206 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 5/100\n",
      "750/750 [==============================] - 636s 848ms/step - loss: 0.3396 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3179 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 6/100\n",
      "750/750 [==============================] - 636s 847ms/step - loss: 0.3414 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3054 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 7/100\n",
      "750/750 [==============================] - 637s 850ms/step - loss: 0.3295 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3210 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 8/100\n",
      "750/750 [==============================] - 633s 843ms/step - loss: 0.3247 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3339 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 9/100\n",
      "750/750 [==============================] - 634s 845ms/step - loss: 0.3206 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3390 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 10/100\n",
      "750/750 [==============================] - 636s 848ms/step - loss: 0.3206 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.2952 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 11/100\n",
      "750/750 [==============================] - 634s 845ms/step - loss: 0.3099 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3461 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 12/100\n",
      "750/750 [==============================] - 633s 844ms/step - loss: 0.3047 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3033 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 13/100\n",
      "750/750 [==============================] - 632s 843ms/step - loss: 0.3019 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3080 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 14/100\n",
      "750/750 [==============================] - 630s 839ms/step - loss: 0.2990 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3121 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 15/100\n",
      "750/750 [==============================] - 632s 842ms/step - loss: 0.2961 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3095 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 16/100\n",
      "750/750 [==============================] - 636s 847ms/step - loss: 0.2968 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3340 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 17/100\n",
      "750/750 [==============================] - 631s 842ms/step - loss: 0.2891 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3202 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 18/100\n",
      "750/750 [==============================] - 632s 842ms/step - loss: 0.2879 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3175 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 19/100\n",
      "750/750 [==============================] - 634s 845ms/step - loss: 0.2821 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3277 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 20/100\n",
      "750/750 [==============================] - 631s 842ms/step - loss: 0.2782 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3255 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 21/100\n",
      "750/750 [==============================] - 632s 843ms/step - loss: 0.2762 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3314 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 22/100\n",
      "750/750 [==============================] - 634s 846ms/step - loss: 0.2716 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3459 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 23/100\n",
      "750/750 [==============================] - 633s 844ms/step - loss: 0.2747 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3366 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 24/100\n",
      "750/750 [==============================] - 635s 846ms/step - loss: 0.2691 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3272 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 25/100\n",
      "750/750 [==============================] - 631s 841ms/step - loss: 0.2691 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3504 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 26/100\n",
      "750/750 [==============================] - 626s 835ms/step - loss: 0.2665 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3448 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 27/100\n",
      "750/750 [==============================] - 630s 840ms/step - loss: 0.2707 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3595 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 28/100\n",
      "750/750 [==============================] - 629s 839ms/step - loss: 0.2622 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3278 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 29/100\n",
      "750/750 [==============================] - 633s 844ms/step - loss: 0.2624 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3418 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 30/100\n",
      "750/750 [==============================] - 633s 844ms/step - loss: 0.2578 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3478 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 31/100\n",
      "750/750 [==============================] - 628s 837ms/step - loss: 0.2608 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3408 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 32/100\n",
      "750/750 [==============================] - 632s 842ms/step - loss: 0.2622 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3540 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 33/100\n",
      "750/750 [==============================] - 636s 847ms/step - loss: 0.2592 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3477 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 34/100\n",
      "750/750 [==============================] - 633s 844ms/step - loss: 0.2505 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3417 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 35/100\n",
      "750/750 [==============================] - 625s 834ms/step - loss: 0.2521 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3619 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 36/100\n",
      "750/750 [==============================] - 626s 835ms/step - loss: 0.2496 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3682 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 37/100\n",
      "750/750 [==============================] - 621s 828ms/step - loss: 0.2461 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3639 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100\n",
      "750/750 [==============================] - 620s 826ms/step - loss: 0.2491 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3685 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 39/100\n",
      "750/750 [==============================] - 621s 828ms/step - loss: 0.2490 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3851 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 40/100\n",
      "750/750 [==============================] - 619s 825ms/step - loss: 0.2415 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3659 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 41/100\n",
      "750/750 [==============================] - 620s 827ms/step - loss: 0.2440 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.4057 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 42/100\n",
      "750/750 [==============================] - 626s 834ms/step - loss: 0.2424 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3684 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 43/100\n",
      "750/750 [==============================] - 621s 828ms/step - loss: 0.2424 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3690 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 44/100\n",
      "750/750 [==============================] - 624s 832ms/step - loss: 0.2439 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3760 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 45/100\n",
      "750/750 [==============================] - 625s 834ms/step - loss: 0.2373 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3803 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 46/100\n",
      "750/750 [==============================] - 626s 835ms/step - loss: 0.2438 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3581 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 47/100\n",
      "750/750 [==============================] - 630s 840ms/step - loss: 0.2326 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3813 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 48/100\n",
      "750/750 [==============================] - 630s 839ms/step - loss: 0.2324 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.4512 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 49/100\n",
      "750/750 [==============================] - 629s 838ms/step - loss: 0.2352 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3922 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 50/100\n",
      "750/750 [==============================] - 635s 847ms/step - loss: 0.2305 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.4333 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 51/100\n",
      "750/750 [==============================] - 630s 840ms/step - loss: 0.2314 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.4204 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 52/100\n",
      "750/750 [==============================] - 631s 841ms/step - loss: 0.2303 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.3850 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 53/100\n",
      "750/750 [==============================] - 633s 844ms/step - loss: 0.2270 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.4011 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 54/100\n",
      "750/750 [==============================] - 635s 847ms/step - loss: 0.2287 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.4232 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 55/100\n",
      "750/750 [==============================] - 634s 846ms/step - loss: 0.2294 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.4045 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 56/100\n",
      "750/750 [==============================] - 636s 849ms/step - loss: 0.2250 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.4459 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 57/100\n",
      "750/750 [==============================] - 633s 844ms/step - loss: 0.2298 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.4040 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 58/100\n",
      "750/750 [==============================] - 637s 849ms/step - loss: 0.2279 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.4849 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 59/100\n",
      "750/750 [==============================] - 640s 853ms/step - loss: 0.2283 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.4436 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 60/100\n",
      "750/750 [==============================] - 637s 849ms/step - loss: 0.2257 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.4940 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 61/100\n",
      "750/750 [==============================] - 637s 850ms/step - loss: 0.2202 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.4531 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 62/100\n",
      "750/750 [==============================] - 640s 853ms/step - loss: 0.2221 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.4489 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 63/100\n",
      "750/750 [==============================] - 646s 861ms/step - loss: 0.2259 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.4532 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 64/100\n",
      "750/750 [==============================] - 652s 869ms/step - loss: 0.2225 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.5585 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 65/100\n",
      "750/750 [==============================] - 681s 908ms/step - loss: 0.2192 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.4187 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 66/100\n",
      "750/750 [==============================] - 698s 930ms/step - loss: 0.2216 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.4659 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 67/100\n",
      "750/750 [==============================] - 726s 968ms/step - loss: 0.2210 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.4469 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 68/100\n",
      "750/750 [==============================] - 658s 877ms/step - loss: 0.2239 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.4161 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 69/100\n",
      "750/750 [==============================] - 647s 862ms/step - loss: 0.2165 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.4753 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 70/100\n",
      "750/750 [==============================] - 651s 867ms/step - loss: 0.2235 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.4429 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 71/100\n",
      "750/750 [==============================] - 643s 858ms/step - loss: 0.2179 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.4748 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 72/100\n",
      "750/750 [==============================] - 643s 858ms/step - loss: 0.2131 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.5858 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 73/100\n",
      "750/750 [==============================] - 702s 936ms/step - loss: 0.2148 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.5134 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 74/100\n",
      "750/750 [==============================] - 664s 885ms/step - loss: 0.2146 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.4640 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100\n",
      "750/750 [==============================] - 638s 851ms/step - loss: 0.2145 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.5510 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 76/100\n",
      "750/750 [==============================] - 637s 849ms/step - loss: 0.2138 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.5789 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 77/100\n",
      "750/750 [==============================] - 638s 851ms/step - loss: 0.2189 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.6021 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 78/100\n",
      "750/750 [==============================] - 635s 847ms/step - loss: 0.2139 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.6215 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 79/100\n",
      "750/750 [==============================] - 4504s 6s/step - loss: 0.2146 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.4380 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 80/100\n",
      "750/750 [==============================] - 789s 1s/step - loss: 0.2119 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.5255 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 81/100\n",
      "750/750 [==============================] - 960s 1s/step - loss: 0.2125 - tp: 5628.0000 - fp: 18372.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2345 - precision: 0.2345 - recall: 1.0000 - auc: 0.5000 - prc: 0.2345 - val_loss: 0.5285 - val_tp: 1399.0000 - val_fp: 4601.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2332 - val_precision: 0.2332 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.2332\n",
      "Epoch 82/100\n",
      "101/750 [===>..........................] - ETA: 7:35 - loss: 0.2072 - tp: 754.0000 - fp: 2478.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2333 - precision: 0.2333 - recall: 1.0000 - auc: 0.5000 - prc: 0.2333"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9k/83m77rxs5835tnj2rh39wf3h0000gn/T/ipykernel_75056/3835200353.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/metis/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/metis/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/metis/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/metis/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/metis/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/opt/anaconda3/envs/metis/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/metis/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(cb_training, epochs=100,validation_data=cb_validation, class_weight = class_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56c0116",
   "metadata": {},
   "source": [
    "# Review \n",
    "## Terrible Accuracy and Weirdness in the TN FN metrics\n",
    "\n",
    "So the accuracy is terrible. Why?  \n",
    "TN and FN are zero - why are they zero? What the heck? \n",
    "* I adjusted the input \n",
    "* I adjusted the class weights \n",
    "* We're not using a CNN after the transfer learning. \n",
    "* Transfer Learning - maybe this didnt actually help? \n",
    "* Did I make a mistake? (Spoiler: Yes)\n",
    "\n",
    "## Checking What Happened \n",
    "We need to figure out why the accuracy dropped so much. So lets go back to the original CNN model with the new spectrograms, and rerun it. \n",
    "### Experiment 1: Run model w/ original class weights, but new spectrograms \n",
    "In notebook 3, we were getting .9 accuracy, even if we were overfitting grossly. If its the new spectrograms, then running that model w/ other parameters the same should drop the accuracy like a rock. \n",
    "\n",
    "### Experiment 2: The class Weights \n",
    "If the new spectrograms dont make the difference, then we also adjusted the class weights. Run the original model with the new class weights, and see if the accuracy drops.  \n",
    "\n",
    "# See you in the Next Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b421dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
