{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05023a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa \n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory, image \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.applications import VGG19, ResNet50\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, GlobalAveragePooling2D, InputLayer, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37c7fb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path.cwd()/'data'\n",
    "answers = pd.read_csv('answers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693e8b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(which_path=2):\n",
    "    if which_path==1:\n",
    "        images_directory = path/'train_images'\n",
    "    else: \n",
    "        images_directory = path/'train_images2'\n",
    "    cb_training = image_dataset_from_directory(images_directory, labels='inferred', image_size=(97,97), subset='training', validation_split=.2, seed=10)\n",
    "    cb_validation = image_dataset_from_directory(images_directory, labels='inferred', image_size=(97,97), subset='validation', validation_split=.2, seed=10)\n",
    "    return (cb_training, cb_validation)\n",
    "\n",
    "\n",
    "def base_set_up(filename, patience=2):\n",
    "    \n",
    "    xx =compute_class_weight(class_weight='balanced',classes=np.unique(answers.label), y=answers.label)\n",
    "    class_weight = dict(zip(np.unique(answers.label), xx))\n",
    "    METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "    ]\n",
    "\n",
    "    earlystop = EarlyStopping(monitor='val_accuracy',verbose=1, patience=patience)\n",
    "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', save_best_only=True, save_weights_only=False, verbose=1)\n",
    "    return (class_weight, METRICS, earlystop, checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146e72cb",
   "metadata": {},
   "source": [
    "# Continue Training Resnet50 w/ cb validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e27fcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30000 files belonging to 2 classes.\n",
      "Using 24000 files for training.\n",
      "Found 30000 files belonging to 2 classes.\n",
      "Using 6000 files for validation.\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/metis/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-22 16:12:36.399320: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 644s 853ms/step - loss: 0.2445 - tp: 5225.0000 - fp: 2453.0000 - tn: 15919.0000 - fn: 403.0000 - accuracy: 0.8810 - precision: 0.6805 - recall: 0.9284 - auc: 0.9612 - prc: 0.8759 - val_loss: 0.2621 - val_tp: 1259.0000 - val_fp: 564.0000 - val_tn: 4037.0000 - val_fn: 140.0000 - val_accuracy: 0.8827 - val_precision: 0.6906 - val_recall: 0.8999 - val_auc: 0.9556 - val_prc: 0.8623\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.88267, saving model to resnet-cb.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/metis/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "750/750 [==============================] - 553s 737ms/step - loss: 0.2388 - tp: 5195.0000 - fp: 2349.0000 - tn: 16023.0000 - fn: 433.0000 - accuracy: 0.8841 - precision: 0.6886 - recall: 0.9231 - auc: 0.9633 - prc: 0.8822 - val_loss: 0.2453 - val_tp: 1229.0000 - val_fp: 480.0000 - val_tn: 4121.0000 - val_fn: 170.0000 - val_accuracy: 0.8917 - val_precision: 0.7191 - val_recall: 0.8785 - val_auc: 0.9552 - val_prc: 0.8609\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.88267 to 0.89167, saving model to resnet-cb.h5\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 474s 632ms/step - loss: 0.2265 - tp: 5245.0000 - fp: 2248.0000 - tn: 16124.0000 - fn: 383.0000 - accuracy: 0.8904 - precision: 0.7000 - recall: 0.9319 - auc: 0.9667 - prc: 0.8950 - val_loss: 0.2353 - val_tp: 1162.0000 - val_fp: 385.0000 - val_tn: 4216.0000 - val_fn: 237.0000 - val_accuracy: 0.8963 - val_precision: 0.7511 - val_recall: 0.8306 - val_auc: 0.9546 - val_prc: 0.8623\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.89167 to 0.89633, saving model to resnet-cb.h5\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 503s 671ms/step - loss: 0.2216 - tp: 5259.0000 - fp: 2161.0000 - tn: 16211.0000 - fn: 369.0000 - accuracy: 0.8946 - precision: 0.7088 - recall: 0.9344 - auc: 0.9680 - prc: 0.8953 - val_loss: 0.2572 - val_tp: 1256.0000 - val_fp: 533.0000 - val_tn: 4068.0000 - val_fn: 143.0000 - val_accuracy: 0.8873 - val_precision: 0.7021 - val_recall: 0.8978 - val_auc: 0.9565 - val_prc: 0.8660\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.89633\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 550s 733ms/step - loss: 0.2164 - tp: 5266.0000 - fp: 2102.0000 - tn: 16270.0000 - fn: 362.0000 - accuracy: 0.8973 - precision: 0.7147 - recall: 0.9357 - auc: 0.9695 - prc: 0.8991 - val_loss: 0.2521 - val_tp: 1240.0000 - val_fp: 485.0000 - val_tn: 4116.0000 - val_fn: 159.0000 - val_accuracy: 0.8927 - val_precision: 0.7188 - val_recall: 0.8863 - val_auc: 0.9572 - val_prc: 0.8685\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.89633\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 597s 797ms/step - loss: 0.2108 - tp: 5267.0000 - fp: 2045.0000 - tn: 16327.0000 - fn: 361.0000 - accuracy: 0.8997 - precision: 0.7203 - recall: 0.9359 - auc: 0.9708 - prc: 0.9034 - val_loss: 0.2307 - val_tp: 1181.0000 - val_fp: 385.0000 - val_tn: 4216.0000 - val_fn: 218.0000 - val_accuracy: 0.8995 - val_precision: 0.7542 - val_recall: 0.8442 - val_auc: 0.9575 - val_prc: 0.8699\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.89633 to 0.89950, saving model to resnet-cb.h5\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 683s 911ms/step - loss: 0.2009 - tp: 5307.0000 - fp: 1916.0000 - tn: 16456.0000 - fn: 321.0000 - accuracy: 0.9068 - precision: 0.7347 - recall: 0.9430 - auc: 0.9735 - prc: 0.9132 - val_loss: 0.2500 - val_tp: 1228.0000 - val_fp: 462.0000 - val_tn: 4139.0000 - val_fn: 171.0000 - val_accuracy: 0.8945 - val_precision: 0.7266 - val_recall: 0.8778 - val_auc: 0.9569 - val_prc: 0.8653\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.89950\n",
      "Epoch 8/10\n",
      "596/750 [======================>.......] - ETA: 1:58 - loss: 0.2017 - tp: 4219.0000 - fp: 1561.0000 - tn: 13034.0000 - fn: 258.0000 - accuracy: 0.9046 - precision: 0.7299 - recall: 0.9424 - auc: 0.9731 - prc: 0.9075"
     ]
    }
   ],
   "source": [
    "# Early stopping \n",
    "\n",
    "# model = None\n",
    "# keras.backend.clear_session()\n",
    "\n",
    "filename = 'resnet-cb.h5'\n",
    "cb_training, cb_validation  = import_data()\n",
    "class_weight, METRICS, earlystop, checkpoint = base_set_up(filename,patience=3)\n",
    "\n",
    "# base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(97,97,3))\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# x = base_model.output\n",
    "# x = Flatten()(x)\n",
    "\n",
    "# x = Dense(500, activation='relu')(x)\n",
    "# x = Dropout(.5)(x)\n",
    "# x = Dense(500, activation='relu')(x)\n",
    "# x = Dropout(.5)(x)\n",
    "\n",
    "\n",
    "# predictions = Dense(1, activation='sigmoid')(x)\n",
    "# optimizer = Adam(learning_rate=0.00001)\n",
    "\n",
    "# # model =  Model(inputs=base_model.input, outputs=predictions)\n",
    "# # model.compile(optimizer=optimizer,loss='binary_crossentropy', metrics=METRICS)\n",
    "\n",
    "\n",
    "model = load_model(filename)\n",
    "history = model.fit(cb_training, epochs=10,validation_data=cb_validation, class_weight = class_weight, callbacks=[earlystop, checkpoint])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
