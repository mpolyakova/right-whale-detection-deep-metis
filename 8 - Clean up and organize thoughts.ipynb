{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e10fcc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa \n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory, image \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, GlobalAveragePooling2D, InputLayer, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils.class_weight import compute_class_weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3202dd7e",
   "metadata": {},
   "source": [
    "# Clean Up Spectrograms \n",
    "So far I've been doing spectrograms 2 ways, and I've gotten confused between them. Lets run them both, and see if we can see the difference. Perhaps I'm missing something simple. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d278686",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path.cwd()/'data'\n",
    "answers = pd.read_csv('answers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fecc97e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_path(row):\n",
    "    file_name = (row['name']+'.jpg')\n",
    "    if row['label']==0:\n",
    "        return images_directory/'no_whale'/file_name\n",
    "    else:\n",
    "        return images_directory/'whale'/file_name\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b2d4e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['name'] = answers['clip_name'].str.split('.').str[0]\n",
    "answers['clip_path']=path/'train'/answers['clip_name']\n",
    "images_directory = path/'train_images'\n",
    "answers['image_path']=answers.apply(get_image_path, axis=1)\n",
    "images_directory = path/'train_images2'\n",
    "answers['image_path2']=answers.apply(get_image_path, axis=1)\n",
    "answers.head()\n",
    "answers.to_csv('answers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e3a5c74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sound(index, df, feature=True):\n",
    "    row = df.iloc[index]\n",
    "    clip_path = row['clip_path']\n",
    "    if feature:\n",
    "        image_path = row['image_path']\n",
    "    else:\n",
    "        image_path = row['image_path2']\n",
    "    y, sr = librosa.load(clip_path, sr=None)\n",
    "    del clip_path, row\n",
    "    return y, sr, image_path, feature \n",
    "\n",
    "def create_spectrogram(input_tuple):\n",
    "    y, sr, output_file,feature = input_tuple\n",
    "    n_fft=192\n",
    "    \n",
    "    fig = plt.figure(figsize=[1, 1])\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    ax.set_frame_on(False)\n",
    "    if feature:\n",
    "        spec = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "        librosa.display.specshow(librosa.power_to_db(spec, ref=np.min))\n",
    "    else:\n",
    "        spec = librosa.stft(y, n_fft=n_fft)\n",
    "        librosa.display.specshow(librosa.power_to_db(spec, ref=np.min),n_fft=n_fft)\n",
    "    plt.savefig(output_file, dpi=97, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "    fig.clf()\n",
    "    plt.close(fig)\n",
    "    plt.close('all')\n",
    "    del spec, fig, ax, y, sr, output_file, input_tuple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f2ec3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [00:10<00:00,  9.21it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(0, 100)):\n",
    "    create_spectrogram(read_sound(i, answers, feature=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24be90f",
   "metadata": {},
   "source": [
    "## Analysis \n",
    "There is a definite difference.The melspectrogram for feature = true, which uses the feature.melspectrogram outputs a much courser grain picture than the stft method, and it doesnt seem affected by the nfft which we're been able to control. We're able to clearly see the grain transformation from the stft. \n",
    "From here on out, we use only the image path 1 - the stft output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92fbf0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 30000/30000 [28:29<00:00, 17.55it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(0, answers.shape[0])):\n",
    "    create_spectrogram(read_sound(i, answers, feature=False))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1231e3b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 30000/30000 [53:42<00:00,  9.31it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(0, answers.shape[0])):\n",
    "    create_spectrogram(read_sound(i, answers, feature=True))   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5697ec68",
   "metadata": {},
   "source": [
    "# Final layer Output\n",
    "\n",
    "In Notebook 4, I made a mistake using softmax without one-hot-encoding my output. Since we are working on a binary problem, our final layer will use sigmoid and binary crossentropy, not softmax. \n",
    "\n",
    "\n",
    "# CNN & Transfer Learning \n",
    "We're tried various CNN's, and we've tried transferlearning using VGG19, but I've mixed up which spectrograms went where \n",
    "\n",
    "# Decided Once\n",
    "Class weights should be assigned once - right below   \n",
    "Metrics  \n",
    "Early stopping  \n",
    "\n",
    "# Next Notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
