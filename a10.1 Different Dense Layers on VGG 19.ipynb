{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05023a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa \n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory, image \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.applications import VGG19, ResNet50\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, GlobalAveragePooling2D, InputLayer, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37c7fb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path.cwd()/'data'\n",
    "answers = pd.read_csv('answers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "693e8b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(which_path=2):\n",
    "    if which_path==1:\n",
    "        images_directory = path/'train_images'\n",
    "    else: \n",
    "        images_directory = path/'train_images2'\n",
    "    cb_training = image_dataset_from_directory(images_directory, labels='inferred', image_size=(97,97), subset='training', validation_split=.2, seed=10)\n",
    "    cb_validation = image_dataset_from_directory(images_directory, labels='inferred', image_size=(97,97), subset='validation', validation_split=.2, seed=10)\n",
    "    return (cb_training, cb_validation)\n",
    "\n",
    "\n",
    "def base_set_up(filename, patience=2):\n",
    "    \n",
    "    xx =compute_class_weight(class_weight='balanced',classes=np.unique(answers.label), y=answers.label)\n",
    "    class_weight = dict(zip(np.unique(answers.label), xx))\n",
    "    METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "    ]\n",
    "\n",
    "    earlystop = EarlyStopping(monitor='val_accuracy',verbose=1, patience=patience)\n",
    "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', save_best_only=True, save_weights_only=False, verbose=1)\n",
    "    return (class_weight, METRICS, earlystop, checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492d997b",
   "metadata": {},
   "source": [
    "# Try different Dense Layer on VGG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e484856c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30000 files belonging to 2 classes.\n",
      "Using 24000 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-22 17:21:26.909890: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30000 files belonging to 2 classes.\n",
      "Using 6000 files for validation.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9k/83m77rxs5835tnj2rh39wf3h0000gn/T/ipykernel_18991/1425660706.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_model2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "filename = 'vgg19-cb-2.h5'\n",
    "cb_training, cb_validation  = import_data()\n",
    "class_weight, METRICS, earlystop, checkpoint = base_set_up(filename)\n",
    "\n",
    "base_model2 = VGG19(weights='imagenet', include_top=False, input_shape=(97,97,3))\n",
    "for layer in base_model2.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x2 = base_model2.output\n",
    "x2 = Flatten()(x)\n",
    "\n",
    "x2 = Dense(100, activation='relu')(x2)\n",
    "x2 = Dropout(.5)(x2)\n",
    "x2 = Dense(100, activation='relu')(x2)\n",
    "x2 = Dropout(.5)(x2)\n",
    "x2 = Dense(100, activation='relu')(x2)\n",
    "x2 = Dropout(.5)(x2)\n",
    "\n",
    "\n",
    "predictions2 = Dense(1, activation='sigmoid')(x2)\n",
    "optimizer = Adam(learning_rate=0.00001)\n",
    "\n",
    "model2 =  Model(inputs=base_model2.input, outputs=predictions2)\n",
    "model2.compile(optimizer=optimizer,loss='binary_crossentropy', metrics=METRICS)\n",
    "\n",
    "history2 = model2.fit(cb_training, epochs=10,validation_data=cb_validation, class_weight = class_weight, callbacks=[earlystop, checkpoint])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
